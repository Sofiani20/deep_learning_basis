{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an Image Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are going to create image classifier. \n",
    "\n",
    "\n",
    "We will use the **Fashion Imnist** Database which is avaible in keras datasets. \n",
    "\n",
    "It contains 10 differents categories images.\n",
    "\n",
    "70 000 images in all (train set: 60 000 , test set: 10 000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fashion_mnist=keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = Fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28) (60000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_full.shape, X_test.shape, y_train_full.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a5ea943d90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train_full[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_full[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 --> T-shirtop ;\n",
    "1 --> Trouser ;\n",
    "2 --> Pullover ;\n",
    "3 --> Dress ;\n",
    "4 --> Coat ;\n",
    "5 --> Sandal ;\n",
    "6 --> Shirt ;\n",
    "7 --> Sneaker ;\n",
    "8 --> Bag ;\n",
    "9 --> Ankle Boot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons créer une liste contenant le nom des 10 classes pour se réferer par les noms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=[\"T-shir/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'T-shir/top'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train_full[10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,  11, 142, 200, 106,   0,   0,\n",
       "          0,   0,   0,   0,   0,  85, 185, 112,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 152, 214, 217, 194, 236, 216, 187,\n",
       "        149, 135, 153, 211, 217, 231, 205, 217, 188,  34,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,  66, 185, 166, 180, 181, 190, 211, 221,\n",
       "        197, 146, 198, 206, 191, 168, 190, 172, 188, 175,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0, 135, 153, 160, 175, 180, 170, 186, 187,\n",
       "        190, 188, 190, 187, 174, 195, 185, 174, 161, 175,  59,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0, 161, 147, 160, 170, 178, 177, 180, 168,\n",
       "        173, 174, 171, 185, 184, 185, 172, 171, 164, 174, 120,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   2, 175, 146, 145, 168, 178, 181, 185, 180,\n",
       "        184, 178, 179, 187, 191, 193, 190, 181, 171, 172, 158,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  35, 177, 155, 140, 151, 172, 191, 187, 186,\n",
       "        187, 186, 187, 182, 191, 194, 188, 180, 161, 161, 185,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  59, 170, 153, 141, 120, 154, 160, 161, 172,\n",
       "        168, 166, 161, 165, 172, 170, 164, 139, 149, 162, 166,  21,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  79, 145, 160, 214, 123, 128, 153, 160, 164,\n",
       "        158, 157, 154, 155, 170, 165, 141, 195, 193, 152, 166,  61,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 100, 157, 225, 245, 175, 113, 174, 158, 158,\n",
       "        160, 155, 160, 164, 178, 188, 135, 185, 240, 201, 172, 108,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,  31, 174,  28, 126, 153, 166, 152, 158,\n",
       "        158, 160, 161, 157, 168, 191, 188,  18, 132, 159,   7,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  82, 187, 159, 153, 157,\n",
       "        158, 162, 164, 164, 154, 187, 190,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   1,   3,   5,   0,  37, 175, 158, 155, 162,\n",
       "        158, 160, 162, 165, 153, 177, 205,   0,   0,   3,   3,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   1,   0,  25, 175, 152, 160, 158,\n",
       "        161, 160, 164, 164, 161, 166, 200,   0,   0,   1,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   4,   0,  30, 171, 147, 164, 155,\n",
       "        165, 161, 165, 162, 170, 164, 162,   0,   0,   2,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   4,   0,  57, 166, 155, 164, 166,\n",
       "        161, 161, 164, 167, 165, 165, 162,  28,   0,   3,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   3,   0, 114, 161, 161, 166, 159,\n",
       "        168, 161, 161, 172, 162, 165, 171,  50,   0,   5,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   1,   0, 149, 157, 167, 172, 159,\n",
       "        172, 164, 161, 172, 170, 160, 171,  89,   0,   4,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   2,   0,   4, 171, 164, 166, 173, 159,\n",
       "        179, 166, 160, 174, 167, 162, 166, 128,   0,   2,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   3,   0,  18, 152, 173, 160, 179, 154,\n",
       "        181, 166, 164, 175, 170, 166, 170, 164,   0,   0,   1,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   4,   0,  47, 165, 172, 167, 185, 153,\n",
       "        187, 173, 165, 174, 179, 166, 166, 158,   5,   0,   3,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   4,   0,  87, 180, 162, 179, 179, 157,\n",
       "        191, 182, 165, 168, 190, 173, 165, 166,  20,   0,   4,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   4,   0, 105, 187, 157, 194, 175, 161,\n",
       "        190, 184, 170, 158, 205, 177, 168, 171,  44,   0,   4,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   5,   0, 138, 181, 158, 205, 160, 167,\n",
       "        190, 198, 167, 152, 218, 186, 170, 172,  57,   0,   5,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   5,   0, 135, 174, 167, 199, 155, 166,\n",
       "        201, 219, 165, 158, 218, 188, 167, 175,  56,   0,   7,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   5,   0, 129, 171, 172, 177, 153, 159,\n",
       "        206, 216, 148, 157, 206, 190, 165, 175,  48,   0,   5,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   5,   0, 167, 187, 182, 198, 194, 200,\n",
       "        226, 240, 184, 206, 255, 197, 178, 179,  42,   0,   5,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   3,   0, 115, 135, 113, 106,  85,  82,\n",
       "        108, 133,  83,  90, 121, 120, 110, 158,  18,   0,   3,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalization\n",
    "We normalize the data dimensions so that theyare approximatively the same scale\n",
    "\n",
    "One way to do that to our data is to divise our data by 255 --> data between 0 and 1\n",
    "\n",
    "NB: La technique la plus utilisée consiste à retrancher la moyenne ensuite diviser par l'écart type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_n=X_train_full/255.  # 255. pour éviter les divisions entières\n",
    "X_test_n=X_test/255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Train set** : use for training the model\n",
    "* **Validation set** : use to optimize the performance of our model. used for tuning the hyperparameters and evaluate the model\n",
    "* **Test set** : used to test the model after the model has gone through initial vetting by validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train= X_train_n[:5000], X_train_n[5000:]\n",
    "y_valid, y_train=y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## there are two ways to create ANN using keras:\n",
    "* sequential model API plus simple\n",
    "* Functional API plus complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.Sequential()     # chaque entrée du layer n-1 sera reliée à chaque neurone du layer n\n",
    "model.add(keras.layers.Flatten(input_shape=[28,28]))  # input layer: chaque image est dans une matrice 28*28 (784 entrées),\n",
    "                                                      # voir help(Flatten) \n",
    "model.add(keras.layers.Dense(300, activation=\"relu\")) # First hidden layer: 300 neurones, chaque entrée est reliée à chacune\n",
    "                                                      # des 300 neurones et pondérée par un poid w_i, soit 235200 + 300 biais\n",
    "                                                      # => 235 500 parametres\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\")) # 2e hidden layer: 100 neurones, les 300 valeurs fournies sur le 1er \n",
    "                                                      # hidden layer après activation seront relièes à chacune des 100 neurones\n",
    "                                                      # + 100 biais => 30100 parametres\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\")) # Out put layer (multiple class, softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Flatten in module keras.layers.core:\n",
      "\n",
      "class Flatten(keras.engine.base_layer.Layer)\n",
      " |  Flatten(*args, **kwargs)\n",
      " |  \n",
      " |  Flattens the input. Does not affect the batch size.\n",
      " |  \n",
      " |  Note: If inputs are shaped `(batch,)` without a feature axis, then\n",
      " |  flattening adds an extra channel dimension and output shape is `(batch, 1)`.\n",
      " |  \n",
      " |  Args:\n",
      " |    data_format: A string,\n",
      " |      one of `channels_last` (default) or `channels_first`.\n",
      " |      The ordering of the dimensions in the inputs.\n",
      " |      `channels_last` corresponds to inputs with shape\n",
      " |      `(batch, ..., channels)` while `channels_first` corresponds to\n",
      " |      inputs with shape `(batch, channels, ...)`.\n",
      " |      It defaults to the `image_data_format` value found in your\n",
      " |      Keras config file at `~/.keras/keras.json`.\n",
      " |      If you never set it, then it will be \"channels_last\".\n",
      " |  \n",
      " |  Example:\n",
      " |  \n",
      " |  >>> model = tf.keras.Sequential()\n",
      " |  >>> model.add(tf.keras.layers.Conv2D(64, 3, 3, input_shape=(3, 32, 32)))\n",
      " |  >>> model.output_shape\n",
      " |  (None, 1, 10, 64)\n",
      " |  \n",
      " |  >>> model.add(Flatten())\n",
      " |  >>> model.output_shape\n",
      " |  (None, 640)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Flatten\n",
      " |      keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      keras.utils.version_utils.LayerVersionSelector\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, data_format=None, **kwargs)\n",
      " |  \n",
      " |  call(self, inputs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      Note here that `call()` method in `tf.keras` is little bit different\n",
      " |      from `keras` API. In `keras` API, you can pass support masking for\n",
      " |      layers as additional arguments. Whereas `tf.keras` has `compute_mask()`\n",
      " |      method to support masking.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Input tensor, or dict/list/tuple of input tensors.\n",
      " |          The first positional `inputs` argument is subject to special rules:\n",
      " |          - `inputs` must be explicitly passed. A layer cannot have zero\n",
      " |            arguments, and `inputs` cannot be provided via the default value\n",
      " |            of a keyword argument.\n",
      " |          - NumPy array or Python scalar values in `inputs` get cast as tensors.\n",
      " |          - Keras mask metadata is only collected from `inputs`.\n",
      " |          - Layers are built (`build(input_shape)` method)\n",
      " |            using shape info from `inputs` only.\n",
      " |          - `input_spec` compatibility is only checked against `inputs`.\n",
      " |          - Mixed precision input casting is only applied to `inputs`.\n",
      " |            If a layer has tensor arguments in `*args` or `**kwargs`, their\n",
      " |            casting behavior in mixed precision should be handled manually.\n",
      " |          - The SavedModel input specification is generated using `inputs` only.\n",
      " |          - Integration with various ecosystem packages like TFMOT, TFLite,\n",
      " |            TF.js, etc is only supported for `inputs` and not for tensors in\n",
      " |            positional and keyword arguments.\n",
      " |        *args: Additional positional arguments. May contain tensors, although\n",
      " |          this is not recommended, for the reasons above.\n",
      " |        **kwargs: Additional keyword arguments. May contain tensors, although\n",
      " |          this is not recommended, for the reasons above.\n",
      " |          The following optional keyword arguments are reserved:\n",
      " |          - `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          - `mask`: Boolean input mask. If the layer's `call()` method takes a\n",
      " |            `mask` argument, its default value will be set to the mask generated\n",
      " |            for `inputs` by the previous layer (if `input` did come from a layer\n",
      " |            that generated a corresponding mask, i.e. if it came from a Keras\n",
      " |            layer with masking support).\n",
      " |      \n",
      " |      Returns:\n",
      " |        A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      If the layer has not been built, this method will call `build` on the\n",
      " |      layer. This assumes that the layer will later be used with inputs that\n",
      " |      match the input shape provided here.\n",
      " |      \n",
      " |      Args:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Note that `get_config()` does not guarantee to return a fresh copy of dict\n",
      " |      every time it is called. The callers should make a copy of the returned dict\n",
      " |      if they want to modify it.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Args:\n",
      " |        *args: Positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: Keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |        - If the layer is not built, the method will call `build`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      " |        RuntimeError: if `super().__init__()` was not called in the constructor.\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_loss(self, losses, **kwargs)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(self, inputs):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Activity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss references\n",
      " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      " |      topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      d = tf.keras.layers.Dense(10)\n",
      " |      x = d(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |            inputs - Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_metric(self, value, name=None, **kwargs)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      This method can be used inside the `call()` method of a subclassed layer\n",
      " |      or model.\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyMetricLayer(tf.keras.layers.Layer):\n",
      " |        def __init__(self):\n",
      " |          super(MyMetricLayer, self).__init__(name='my_metric_layer')\n",
      " |          self.mean = tf.keras.metrics.Mean(name='metric_1')\n",
      " |      \n",
      " |        def call(self, inputs):\n",
      " |          self.add_metric(self.mean(inputs))\n",
      " |          self.add_metric(tf.reduce_sum(inputs), name='metric_2')\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any tensor passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      metrics become part of the model's topology and are tracked when you\n",
      " |      save the model via `save()`.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Note: Calling `add_metric()` with the result of a metric object on a\n",
      " |      Functional Model, as shown in the example below, is not supported. This is\n",
      " |      because we cannot trace the metric result tensor back to the model's inputs.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        name: String metric name.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |          `aggregation` - When the `value` tensor provided is not the result of\n",
      " |          calling a `keras.Metric` instance, it will be aggregated by default\n",
      " |          using a `keras.Metric.Mean`.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add update op(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Args:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |        inputs: Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregationV2.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
      " |          `collections`, `experimental_autocast` and `caching_device`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The variable created.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  apply(self, inputs, *args, **kwargs)\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      This is an alias of `self.__call__`.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the variables of the layer (optional, for subclass implementers).\n",
      " |      \n",
      " |      This is a method that implementers of subclasses of `Layer` or `Model`\n",
      " |      can override if they need a state-creation step in-between\n",
      " |      layer instantiation and layer call.\n",
      " |      \n",
      " |      This is typically used to create the weights of `Layer` subclasses.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_shape: Instance of `TensorShape`, or list of instances of\n",
      " |          `TensorShape` if the layer expects a list of inputs\n",
      " |          (one instance per input).\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
      " |          how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  finalize_state(self)\n",
      " |      Finalizes the layers state after updating layer weights.\n",
      " |      \n",
      " |      This function can be subclassed in a layer and will be called after updating\n",
      " |      a layer weights. It can be overridden to finalize any additional layer state\n",
      " |      after a weight update.\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first input node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      Retrieves losses relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of loss tensors of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first output node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      Retrieves updates relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of update ops of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer, as NumPy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      returns both trainable and non-trainable weight values associated with this\n",
      " |      layer as a list of NumPy arrays, which can in turn be used to load state\n",
      " |      into similarly parameterized layers.\n",
      " |      \n",
      " |      For example, a `Dense` layer returns a list of two values: the kernel matrix\n",
      " |      and the bias vector. These can be used to set the weights of another\n",
      " |      `Dense` layer:\n",
      " |      \n",
      " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> layer_a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Returns:\n",
      " |          Weights values as a list of NumPy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from NumPy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      sets the weight values from numpy arrays. The weight values should be\n",
      " |      passed in the order they are created by the layer. Note that the layer's\n",
      " |      weights must be instantiated before calling this function, by calling\n",
      " |      the layer.\n",
      " |      \n",
      " |      For example, a `Dense` layer returns a list of two values: the kernel matrix\n",
      " |      and the bias vector. These can be used to set the weights of another\n",
      " |      `Dense` layer:\n",
      " |      \n",
      " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> layer_a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Args:\n",
      " |        weights: a list of NumPy arrays. The number\n",
      " |          of arrays and their shape must match\n",
      " |          number of the dimensions of the weights\n",
      " |          of the layer (i.e. it should match the\n",
      " |          output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If the provided weights list does not match the\n",
      " |          layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Args:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  compute_dtype\n",
      " |      The dtype of the layer's computations.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.compute_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.dtype`, the dtype of\n",
      " |      the weights.\n",
      " |      \n",
      " |      Layers automatically cast their inputs to the compute dtype, which causes\n",
      " |      computations and the output to be in the compute dtype as well. This is done\n",
      " |      by the base Layer class in `Layer.__call__`, so you do not have to insert\n",
      " |      these casts if implementing your own layer.\n",
      " |      \n",
      " |      Layers often perform certain internal computations in higher precision when\n",
      " |      `compute_dtype` is float16 or bfloat16 for numeric stability. The output\n",
      " |      will still typically be float16 or bfloat16 in such cases.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The layer's compute dtype.\n",
      " |  \n",
      " |  dtype\n",
      " |      The dtype of the layer weights.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.variable_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.compute_dtype`, the\n",
      " |      dtype of the layer's computations.\n",
      " |  \n",
      " |  dtype_policy\n",
      " |      The dtype policy associated with this layer.\n",
      " |      \n",
      " |      This is an instance of a `tf.keras.mixed_precision.Policy`.\n",
      " |  \n",
      " |  dynamic\n",
      " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  losses\n",
      " |      List of losses added using the `add_loss()` API.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> class MyLayer(tf.keras.layers.Layer):\n",
      " |      ...   def call(self, inputs):\n",
      " |      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |      ...     return inputs\n",
      " |      >>> l = MyLayer()\n",
      " |      >>> l(np.ones((10, 1)))\n",
      " |      >>> l.losses\n",
      " |      [1.0]\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Activity regularization.\n",
      " |      >>> len(model.losses)\n",
      " |      0\n",
      " |      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      >>> len(model.losses)\n",
      " |      1\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')\n",
      " |      >>> x = d(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Weight regularization.\n",
      " |      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      >>> model.losses\n",
      " |      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  metrics\n",
      " |      List of metrics added using the `add_metric()` API.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      >>> input = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> d = tf.keras.layers.Dense(2)\n",
      " |      >>> output = d(input)\n",
      " |      >>> d.add_metric(tf.reduce_max(output), name='max')\n",
      " |      >>> d.add_metric(tf.reduce_min(output), name='min')\n",
      " |      >>> [m.name for m in d.metrics]\n",
      " |      ['max', 'min']\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of `Metric` objects.\n",
      " |  \n",
      " |  name\n",
      " |      Name of the layer (string), set in the constructor.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |      Sequence of non-trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |      List of all non-trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Non-trainable weights are *not* updated during training. They are expected\n",
      " |      to be updated manually in `call()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of non-trainable variables.\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  trainable_weights\n",
      " |      List of all trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Trainable weights are updated via gradient descent during training.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of trainable variables.\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variable_dtype\n",
      " |      Alias of `Layer.dtype`, the dtype of the weights.\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
      " |      themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  input_spec\n",
      " |      `InputSpec` instance(s) describing the input format for this layer.\n",
      " |      \n",
      " |      When you create a layer subclass, you can set `self.input_spec` to enable\n",
      " |      the layer to run input compatibility checks when it is called.\n",
      " |      Consider a `Conv2D` layer: it can only be called on a single input tensor\n",
      " |      of rank 4. As such, you can set, in `__init__()`:\n",
      " |      \n",
      " |      ```python\n",
      " |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
      " |      ```\n",
      " |      \n",
      " |      Now, if you try to call the layer on an input that isn't rank 4\n",
      " |      (for instance, an input of shape `(2,)`, it will raise a nicely-formatted\n",
      " |      error:\n",
      " |      \n",
      " |      ```\n",
      " |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
      " |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
      " |      ```\n",
      " |      \n",
      " |      Input checks that can be specified via `input_spec` include:\n",
      " |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
      " |      - Shape\n",
      " |      - Rank (ndim)\n",
      " |      - Dtype\n",
      " |      \n",
      " |      For more information, see `tf.keras.layers.InputSpec`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  supports_masking\n",
      " |      Whether this layer supports computing a mask using `compute_mask`.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from builtins.type\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      >>> class MyModule(tf.Module):\n",
      " |      ...   @tf.Module.with_name_scope\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      " |      ...     return tf.matmul(x, self.w)\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      >>> mod = MyModule()\n",
      " |      >>> mod(tf.ones([1, 2]))\n",
      " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      " |      >>> mod.w\n",
      " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      " |      numpy=..., dtype=float32)>\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      >>> a = tf.Module()\n",
      " |      >>> b = tf.Module()\n",
      " |      >>> c = tf.Module()\n",
      " |      >>> a.b = b\n",
      " |      >>> b.c = c\n",
      " |      >>> list(a.submodules) == [b, c]\n",
      " |      True\n",
      " |      >>> list(b.submodules) == [c]\n",
      " |      True\n",
      " |      >>> list(c.submodules) == []\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from keras.utils.version_utils.LayerVersionSelector:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(keras.layers.Flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()  # none signifie qu'on a fournie toutes les données d'entrée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can look at our neural network's structure by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pydot\n",
    "keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we can access the parameters by using get_weight() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biais = model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02448617, -0.00877795, -0.02189048, ..., -0.02766046,\n",
       "         0.03859074, -0.06889391],\n",
       "       [ 0.00476504, -0.03105379, -0.0586676 , ...,  0.00602964,\n",
       "        -0.02763776, -0.04165364],\n",
       "       [-0.06189284, -0.06901957,  0.07102345, ..., -0.04238207,\n",
       "         0.07121518, -0.07331658],\n",
       "       ...,\n",
       "       [-0.03048757,  0.02155137, -0.05400612, ..., -0.00113463,\n",
       "         0.00228987,  0.05581069],\n",
       "       [ 0.07061854, -0.06960931,  0.07038955, ..., -0.00384101,\n",
       "         0.00034875,  0.02878492],\n",
       "       [-0.06022581,  0.01577859, -0.02585464, ..., -0.00527829,\n",
       "         0.00272203, -0.06793761]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights # les valeurs iniatialement affectée aux poids w_i pour lancer la descent de gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biais # biais initialisés à 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biais.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set up learning process\n",
    "\n",
    "https://keras.io/api/models/model_training_apis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method compile in module keras.engine.training:\n",
      "\n",
      "compile(optimizer='rmsprop', loss=None, metrics=None, loss_weights=None, weighted_metrics=None, run_eagerly=None, steps_per_execution=None, **kwargs) method of keras.engine.sequential.Sequential instance\n",
      "    Configures the model for training.\n",
      "    \n",
      "    Example:\n",
      "    \n",
      "    ```python\n",
      "    model.compile(optimizer=tf.keras.optimizer.Adam(learning_rate=1e-3),\n",
      "                  loss=tf.keras.losses.BinaryCrossentropy(),\n",
      "                  metrics=[tf.keras.metrics.BinaryAccuracy(),\n",
      "                           tf.keras.metrics.FalseNegatives()])\n",
      "    ```\n",
      "    \n",
      "    Args:\n",
      "        optimizer: String (name of optimizer) or optimizer instance. See\n",
      "          `tf.keras.optimizers`.\n",
      "        loss: Loss function. Maybe be a string (name of loss function), or\n",
      "          a `tf.keras.losses.Loss` instance. See `tf.keras.losses`. A loss\n",
      "          function is any callable with the signature `loss = fn(y_true,\n",
      "          y_pred)`, where `y_true` are the ground truth values, and\n",
      "          `y_pred` are the model's predictions.\n",
      "          `y_true` should have shape\n",
      "          `(batch_size, d0, .. dN)` (except in the case of\n",
      "          sparse loss functions such as\n",
      "          sparse categorical crossentropy which expects integer arrays of shape\n",
      "          `(batch_size, d0, .. dN-1)`).\n",
      "          `y_pred` should have shape `(batch_size, d0, .. dN)`.\n",
      "          The loss function should return a float tensor.\n",
      "          If a custom `Loss` instance is\n",
      "          used and reduction is set to `None`, return value has shape\n",
      "          `(batch_size, d0, .. dN-1)` i.e. per-sample or per-timestep loss\n",
      "          values; otherwise, it is a scalar. If the model has multiple outputs,\n",
      "          you can use a different loss on each output by passing a dictionary\n",
      "          or a list of losses. The loss value that will be minimized by the\n",
      "          model will then be the sum of all individual losses, unless\n",
      "          `loss_weights` is specified.\n",
      "        metrics: List of metrics to be evaluated by the model during training\n",
      "          and testing. Each of this can be a string (name of a built-in\n",
      "          function), function or a `tf.keras.metrics.Metric` instance. See\n",
      "          `tf.keras.metrics`. Typically you will use `metrics=['accuracy']`. A\n",
      "          function is any callable with the signature `result = fn(y_true,\n",
      "          y_pred)`. To specify different metrics for different outputs of a\n",
      "          multi-output model, you could also pass a dictionary, such as\n",
      "          `metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}`.\n",
      "          You can also pass a list to specify a metric or a list of metrics\n",
      "          for each output, such as `metrics=[['accuracy'], ['accuracy', 'mse']]`\n",
      "          or `metrics=['accuracy', ['accuracy', 'mse']]`. When you pass the\n",
      "          strings 'accuracy' or 'acc', we convert this to one of\n",
      "          `tf.keras.metrics.BinaryAccuracy`,\n",
      "          `tf.keras.metrics.CategoricalAccuracy`,\n",
      "          `tf.keras.metrics.SparseCategoricalAccuracy` based on the loss\n",
      "          function used and the model output shape. We do a similar\n",
      "          conversion for the strings 'crossentropy' and 'ce' as well.\n",
      "        loss_weights: Optional list or dictionary specifying scalar coefficients\n",
      "          (Python floats) to weight the loss contributions of different model\n",
      "          outputs. The loss value that will be minimized by the model will then\n",
      "          be the *weighted sum* of all individual losses, weighted by the\n",
      "          `loss_weights` coefficients.\n",
      "            If a list, it is expected to have a 1:1 mapping to the model's\n",
      "              outputs. If a dict, it is expected to map output names (strings)\n",
      "              to scalar coefficients.\n",
      "        weighted_metrics: List of metrics to be evaluated and weighted by\n",
      "          `sample_weight` or `class_weight` during training and testing.\n",
      "        run_eagerly: Bool. Defaults to `False`. If `True`, this `Model`'s\n",
      "          logic will not be wrapped in a `tf.function`. Recommended to leave\n",
      "          this as `None` unless your `Model` cannot be run inside a\n",
      "          `tf.function`. `run_eagerly=True` is not supported when using\n",
      "          `tf.distribute.experimental.ParameterServerStrategy`.\n",
      "        steps_per_execution: Int. Defaults to 1. The number of batches to\n",
      "          run during each `tf.function` call. Running multiple batches\n",
      "          inside a single `tf.function` call can greatly improve performance\n",
      "          on TPUs or small models with a large Python overhead.\n",
      "          At most, one full epoch will be run each\n",
      "          execution. If a number larger than the size of the epoch is passed,\n",
      "          the execution will be truncated to the size of the epoch.\n",
      "          Note that if `steps_per_execution` is set to `N`,\n",
      "          `Callback.on_batch_begin` and `Callback.on_batch_end` methods\n",
      "          will only be called every `N` batches\n",
      "          (i.e. before/after each `tf.function` execution).\n",
      "        **kwargs: Arguments supported for backwards compatibility only.\n",
      "    \n",
      "    Raises:\n",
      "        ValueError: In case of invalid arguments for\n",
      "            `optimizer`, `loss` or `metrics`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model.compile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la fonction coût: loss --> sparse categorical crossentropy car notre data set a 10 catégories labelisées\n",
    "# si nous avons les proba d'appartenance aux class il faura utiliser categorical croos entropy, si 1 et 0 seulement\n",
    "# il faut utiliser binary cross entropy\n",
    "\n",
    "# optimizer: stochastic gradient descent pour sgd\n",
    "\n",
    "# metrics = 'accurary' car nous faisons une classification, si regression il faut utilise mse\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer= 'sgd',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### difference between batch and epoch\n",
    "https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/#:~:text=The%20number%20of%20epochs%20is%20a%20hyperparameter%20that,epoch%20is%20comprised%20of%20one%20or%20more%20batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.7237 - accuracy: 0.7644 - val_loss: 0.5207 - val_accuracy: 0.8234\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4843 - accuracy: 0.8318 - val_loss: 0.4345 - val_accuracy: 0.8538\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4393 - accuracy: 0.8454 - val_loss: 0.5330 - val_accuracy: 0.7980\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4125 - accuracy: 0.8569 - val_loss: 0.3915 - val_accuracy: 0.8644\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3940 - accuracy: 0.8619 - val_loss: 0.3748 - val_accuracy: 0.8690\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3752 - accuracy: 0.8674 - val_loss: 0.3707 - val_accuracy: 0.8722\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3633 - accuracy: 0.8714 - val_loss: 0.3627 - val_accuracy: 0.8722\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3519 - accuracy: 0.8750 - val_loss: 0.3842 - val_accuracy: 0.8630\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3416 - accuracy: 0.8785 - val_loss: 0.3598 - val_accuracy: 0.8704\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3322 - accuracy: 0.8825 - val_loss: 0.3432 - val_accuracy: 0.8770\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3243 - accuracy: 0.8830 - val_loss: 0.3438 - val_accuracy: 0.8780\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3151 - accuracy: 0.8868 - val_loss: 0.3305 - val_accuracy: 0.8814\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3082 - accuracy: 0.8890 - val_loss: 0.3263 - val_accuracy: 0.8878\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3023 - accuracy: 0.8916 - val_loss: 0.3397 - val_accuracy: 0.8776\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2948 - accuracy: 0.8940 - val_loss: 0.3217 - val_accuracy: 0.8848\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2893 - accuracy: 0.8970 - val_loss: 0.3094 - val_accuracy: 0.8894\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2841 - accuracy: 0.8977 - val_loss: 0.3565 - val_accuracy: 0.8730\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2779 - accuracy: 0.9001 - val_loss: 0.3135 - val_accuracy: 0.8896\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2730 - accuracy: 0.9022 - val_loss: 0.3114 - val_accuracy: 0.8898\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2676 - accuracy: 0.9034 - val_loss: 0.3270 - val_accuracy: 0.8820\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2626 - accuracy: 0.9056 - val_loss: 0.3058 - val_accuracy: 0.8924\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2578 - accuracy: 0.9075 - val_loss: 0.2971 - val_accuracy: 0.8968\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2537 - accuracy: 0.9080 - val_loss: 0.2980 - val_accuracy: 0.8922\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2487 - accuracy: 0.9104 - val_loss: 0.3082 - val_accuracy: 0.8880\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2444 - accuracy: 0.9124 - val_loss: 0.2983 - val_accuracy: 0.8942\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2408 - accuracy: 0.9135 - val_loss: 0.3061 - val_accuracy: 0.8896\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2365 - accuracy: 0.9154 - val_loss: 0.3042 - val_accuracy: 0.8944\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2329 - accuracy: 0.9164 - val_loss: 0.2996 - val_accuracy: 0.8920\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2285 - accuracy: 0.9182 - val_loss: 0.3059 - val_accuracy: 0.8908\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2253 - accuracy: 0.9193 - val_loss: 0.3027 - val_accuracy: 0.8920\n"
     ]
    }
   ],
   "source": [
    "# The number of epochs is a hyperparameter that defines the number times that the learning algorithm will work through \n",
    "# the entire training dataset.\n",
    "\n",
    "# on ajouter l parametre class_weight() si les classes ne sont uniformément reparties\n",
    "model_history=model.fit(X_train, y_train, epochs=30,\n",
    "                       validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 1, 'epochs': 30, 'steps': 1719}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.7236780524253845,\n",
       "  0.4843233525753021,\n",
       "  0.43925395607948303,\n",
       "  0.41249433159828186,\n",
       "  0.39395850896835327,\n",
       "  0.37522026896476746,\n",
       "  0.36334460973739624,\n",
       "  0.35189977288246155,\n",
       "  0.3415890038013458,\n",
       "  0.33219200372695923,\n",
       "  0.32431620359420776,\n",
       "  0.31506234407424927,\n",
       "  0.30816128849983215,\n",
       "  0.3023137152194977,\n",
       "  0.29484379291534424,\n",
       "  0.289277583360672,\n",
       "  0.2841065526008606,\n",
       "  0.277920126914978,\n",
       "  0.27297961711883545,\n",
       "  0.26764771342277527,\n",
       "  0.26259559392929077,\n",
       "  0.2577607333660126,\n",
       "  0.253675252199173,\n",
       "  0.24865274131298065,\n",
       "  0.24440625309944153,\n",
       "  0.24075055122375488,\n",
       "  0.23647968471050262,\n",
       "  0.23291146755218506,\n",
       "  0.22853097319602966,\n",
       "  0.22528870403766632],\n",
       " 'accuracy': [0.7644181847572327,\n",
       "  0.8317636251449585,\n",
       "  0.8453817963600159,\n",
       "  0.8568727374076843,\n",
       "  0.8618909120559692,\n",
       "  0.8673818111419678,\n",
       "  0.871399998664856,\n",
       "  0.875,\n",
       "  0.8785272836685181,\n",
       "  0.8825091123580933,\n",
       "  0.8830181956291199,\n",
       "  0.8867999911308289,\n",
       "  0.889018177986145,\n",
       "  0.8916181921958923,\n",
       "  0.893963634967804,\n",
       "  0.8969636559486389,\n",
       "  0.8976545333862305,\n",
       "  0.9000909328460693,\n",
       "  0.9021818041801453,\n",
       "  0.9034000039100647,\n",
       "  0.9055818319320679,\n",
       "  0.9075272679328918,\n",
       "  0.907981812953949,\n",
       "  0.9104363918304443,\n",
       "  0.9124363660812378,\n",
       "  0.9134727120399475,\n",
       "  0.915363609790802,\n",
       "  0.9163636565208435,\n",
       "  0.918181836605072,\n",
       "  0.9192909002304077],\n",
       " 'val_loss': [0.5206756591796875,\n",
       "  0.43450361490249634,\n",
       "  0.5330292582511902,\n",
       "  0.391543447971344,\n",
       "  0.374805212020874,\n",
       "  0.3706672489643097,\n",
       "  0.36266204714775085,\n",
       "  0.38417407870292664,\n",
       "  0.35976341366767883,\n",
       "  0.34315529465675354,\n",
       "  0.34380123019218445,\n",
       "  0.3304961919784546,\n",
       "  0.32629290223121643,\n",
       "  0.3397334814071655,\n",
       "  0.32173413038253784,\n",
       "  0.3094216287136078,\n",
       "  0.3565293252468109,\n",
       "  0.31350135803222656,\n",
       "  0.3113585114479065,\n",
       "  0.32696688175201416,\n",
       "  0.3057759702205658,\n",
       "  0.29714417457580566,\n",
       "  0.29797956347465515,\n",
       "  0.30816563963890076,\n",
       "  0.2983236014842987,\n",
       "  0.306073397397995,\n",
       "  0.30421584844589233,\n",
       "  0.29962167143821716,\n",
       "  0.30589476227760315,\n",
       "  0.302684485912323],\n",
       " 'val_accuracy': [0.8234000205993652,\n",
       "  0.8537999987602234,\n",
       "  0.7979999780654907,\n",
       "  0.8644000291824341,\n",
       "  0.8690000176429749,\n",
       "  0.8722000122070312,\n",
       "  0.8722000122070312,\n",
       "  0.8629999756813049,\n",
       "  0.8704000115394592,\n",
       "  0.8769999742507935,\n",
       "  0.878000020980835,\n",
       "  0.8813999891281128,\n",
       "  0.8877999782562256,\n",
       "  0.8776000142097473,\n",
       "  0.8848000168800354,\n",
       "  0.8894000053405762,\n",
       "  0.8730000257492065,\n",
       "  0.8895999789237976,\n",
       "  0.8898000121116638,\n",
       "  0.8820000290870667,\n",
       "  0.8924000263214111,\n",
       "  0.8967999815940857,\n",
       "  0.8921999931335449,\n",
       "  0.8880000114440918,\n",
       "  0.8942000269889832,\n",
       "  0.8895999789237976,\n",
       "  0.8944000005722046,\n",
       "  0.8920000195503235,\n",
       "  0.8907999992370605,\n",
       "  0.8920000195503235]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_history.history # to get loss accuracy and val_accuracy informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(model_history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)          # val_loss: validation loss\n",
    "plt.show()                       # val_accuracy: validation accurary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "si on ajoute d'autre epoch keras.fit continuera à partir de 30 là où l'entrainement s'est arrêté"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing performance on a test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3361 - accuracy: 0.8834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3360535800457001, 0.883400022983551]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_n,y_test) # [loss  , accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new=X_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba=model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-eb6aa9c3282e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_predict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "y_predict=model.predict_classes(X_new)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=np.argmax(model.predict(X_new), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U10')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### comparons les 3 predictions aux vraies images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesImage(54,36;334.8x217.44)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(plt.imshow(X_test[0])) # bonne prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesImage(54,36;334.8x217.44)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(plt.imshow(X_test[1])) # bonne prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesImage(54,36;334.8x217.44)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(plt.imshow(X_test[2])) # bonne prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
